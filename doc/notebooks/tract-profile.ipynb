{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is already in place. If you want to fetch it again please first remove the folder /Users/arokem/AFQ_data/templates \n"
     ]
    }
   ],
   "source": [
    "import AFQ.utils.streamlines as aus\n",
    "import AFQ.segmentation as afs\n",
    "import AFQ.data as afd\n",
    "import AFQ.tractography as aft\n",
    "import AFQ.registration as reg\n",
    "import AFQ.dti as dti\n",
    "import AFQ.segmentation as seg\n",
    "\n",
    "import nibabel as nib\n",
    "import dipy.data as dpd\n",
    "from dipy.data import fetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is already in place. If you want to fetch it again please first remove the folder /Users/arokem/.dipy/stanford_hardi \n"
     ]
    }
   ],
   "source": [
    "dpd.fetch_stanford_hardi()\n",
    "hardi_dir = op.join(fetcher.dipy_home, \"stanford_hardi\")\n",
    "hardi_fdata = op.join(hardi_dir, \"HARDI150.nii.gz\")\n",
    "hardi_fbval = op.join(hardi_dir, \"HARDI150.bval\")\n",
    "hardi_fbvec = op.join(hardi_dir, \"HARDI150.bvec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = nib.load(hardi_fdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not op.exists('./dti_FA.nii.gz'):\n",
    "    dti_params = dti.fit_dti(hardi_fdata, hardi_fbval, hardi_fbvec, out_dir='.')\n",
    "else:\n",
    "    dti_params = {'AD': './dti_AD.nii.gz',\n",
    "                  'FA': './dti_FA.nii.gz',\n",
    "                  'MD': './dti_MD.nii.gz',\n",
    "                  'RD': './dti_RD.nii.gz',\n",
    "                  'params': './dti_params.nii.gz'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not op.exists('dti_streamlines.trk'):\n",
    "    streamlines = list(aft.track(dti_params['params']))\n",
    "    aus.write_trk('dti_streamlines.trk', streamlines, affine=img.affine)\n",
    "else: \n",
    "    streamlines = aus.read_trk('dti_streamlines.trk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is already in place. If you want to fetch it again please first remove the folder /Users/arokem/AFQ_data/templates \n"
     ]
    }
   ],
   "source": [
    "templates = afd.read_templates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bundle_names = [\"ATR\", \"CGC\", \"CST\",\n",
    "#                # \"FA\", \"FP\",\n",
    "#                \"HCC\", \"IFO\", \"ILF\",\n",
    "#                \"SLF\", \"ARC\", \"UNC\"]\n",
    "bundle_names = [\"ARC\", \"CST\"]\n",
    "# For the arcuate, we need to rename a few of these and duplicate the SLF ROI:\n",
    "templates['ARC_roi1_L'] = templates['SLF_roi1_L']\n",
    "templates['ARC_roi1_R'] = templates['SLF_roi1_R']\n",
    "templates['ARC_roi2_L'] = templates['SLFt_roi2_L']\n",
    "templates['ARC_roi2_R'] = templates['SLFt_roi2_R']\n",
    "\n",
    "bundles = {}\n",
    "\n",
    "for name in bundle_names:\n",
    "    for hemi in ['_R', '_L']:\n",
    "        bundles[name + hemi] = {'ROIs': [templates[name + '_roi1' + hemi], \n",
    "                                         templates[name + '_roi1' + hemi]],\n",
    "                                'rules' : [True, True]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size is approximately 35MB\n",
      "Dataset is already in place. If you want to fetch it again please first remove the folder /Users/arokem/.dipy/mni_template \n"
     ]
    }
   ],
   "source": [
    "MNI_T2_img = dpd.read_mni_template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not op.exists('mapping.nii.gz'):\n",
    "    mapping = reg.syn_register_dwi(dwi, gtab)\n",
    "else: \n",
    "    mapping = reg.read_mapping('mapping.nii.gz',img, MNI_T2_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size is approximately 35MB\n",
      "Dataset is already in place. If you want to fetch it again please first remove the folder /Users/arokem/.dipy/mni_template "
     ]
    }
   ],
   "source": [
    "fiber_groups = seg.segment(hardi_fdata,\n",
    "                           hardi_fbval,\n",
    "                           hardi_fbvec,\n",
    "                           streamlines,\n",
    "                           bundles,\n",
    "                           mapping=mapping,\n",
    "                           as_generator=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FA_img = nib.load('./dti_FA.nii.gz')\n",
    "FA_data = FA_img.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bundles.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "imp.reload(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for bundle in bundles:\n",
    "    fig, ax = plt.subplots(1)\n",
    "    w = seg.gaussian_weights(fiber_groups[bundle])\n",
    "    profile = seg.calculate_tract_profile(FA_data, fiber_groups[bundle], weights=w)\n",
    "    ax.plot(profile)\n",
    "    ax.set_title(bundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
